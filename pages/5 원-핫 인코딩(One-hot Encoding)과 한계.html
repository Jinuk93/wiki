<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>텍스트 벡터화 : 원-핫 인코딩에서 워드 임베딩까지</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@400;700;900&display=swap" rel="stylesheet">
    <style>
        /* 1. Core Design Philosophy & Technical Specs */
        :root {
            --color-text-primary: #212529;
            --color-text-secondary: #6c757d;
            --color-border: #dee2e6;
            --color-bg-white: #ffffff;
            --color-bg-subtle: #f8f9fa;
            --font-family-base: 'Noto Sans KR', sans-serif;
        }

        html {
            scroll-behavior: smooth;
        }

        body {
            font-family: var(--font-family-base);
            font-size: 1rem; /* 16px */
            line-height: 1.7;
            background-color: var(--color-bg-white);
            color: var(--color-text-primary);
            margin: 0;
            padding: 4rem 1rem;
            -webkit-font-smoothing: antialiased;
        }

        /* 2. Typography & Hierarchy */
        h1, h2, h3 {
            font-weight: 700;
            line-height: 1.3;
            margin-top: 0;
        }

        h1 {
            font-size: 2.5rem;
            font-weight: 900;
            margin-bottom: 0.5rem;
        }

        h2 {
            font-size: 2rem;
            margin-bottom: 0.75rem;
        }

        h3 {
            font-size: 1.5rem;
            margin-bottom: 1rem;
            margin-top: 2rem;
            padding-bottom: 0.5rem;
            border-bottom: 1px solid var(--color-border);
        }
        
        h3:first-of-type {
            margin-top: 0;
        }

        p {
            margin-top: 0;
            margin-bottom: 1rem;
        }
        
        strong, b {
           font-weight: 700;
           color: var(--color-text-primary);
        }
        
        code {
            font-family: Consolas, 'Courier New', monospace;
            background-color: #e9ecef;
            padding: 0.2em 0.4em;
            border-radius: 4px;
            font-size: 90%;
        }

        /* 3. Component Library & Structure */
        .container {
            max-width: 800px;
            margin: 0 auto;
        }

        .header, .section-title {
            text-align: center;
            margin-bottom: 3rem;
        }
        
        .header {
            margin-top: 0;
        }

        .header p, .section-title p {
            font-size: 1.125rem;
            color: var(--color-text-secondary);
            max-width: 600px;
            margin-left: auto;
            margin-right: auto;
            margin-bottom: 0;
        }

        .card {
            background-color: var(--color-bg-white);
            border: 1px solid var(--color-border);
            border-radius: 0.75rem;
            padding: 2.5rem;
            margin-bottom: 1.5rem;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.02);
            transition: transform 0.3s ease, box-shadow 0.3s ease;
        }

        .card:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 20px rgba(0, 0, 0, 0.07);
        }
        
        aside {
            background-color: var(--color-bg-subtle);
            border-left: 4px solid var(--color-border);
            padding: 1rem 1.5rem;
            margin: 1.5rem 0;
            border-radius: 0 0.25rem 0.25rem 0;
            font-size: 0.95rem;
        }
        
        aside p:last-child, aside ul:last-child, aside ol:last-child {
            margin-bottom: 0;
        }
        
        aside ul, aside ol, .card ul, .card ol {
            padding-left: 1.2rem;
        }
        
        .highlight-gray {
            background-color: var(--color-bg-subtle);
        }

        .transition-text {
            text-align: center;
            max-width: 700px;
            margin: 3rem auto;
            font-size: 1.1rem;
            line-height: 1.8;
            color: #495057;
        }
        
        .fade-in-up {
            opacity: 0;
            transform: translateY(30px);
            transition: opacity 0.6s ease-out, transform 0.6s ease-out;
        }

        .fade-in-up.visible {
            opacity: 1;
            transform: translateY(0);
        }
    </style>
</head>
<body>

    <main class="container">
        <header class="header fade-in-up">
            <h1>텍스트 벡터화<br>: 원-핫 인코딩에서 워드 임베딩까지</h1>
        </header>

        <p class="transition-text fade-in-up">
            자연어 처리(NLP)에서 모델을 학습시키기 위해서는, 문자 형태의 텍스트를 기계가 이해할 수 있는 숫자 형태, 즉 <strong>벡터(Vector)</strong>로 변환하는 과정이 필수적입니다. 이를 <strong>벡터화(Vectorization)</strong>라고 하며, 가장 기초적인 방법인 <strong>원-핫 인코딩</strong>부터 현대적인 방식인 <strong>워드 임베딩</strong>까지 알아보겠습니다.
        </p>

        <div class="section-title fade-in-up">
            <h2>1. 원-핫 인코딩 (One-hot Encoding)</h2>
        </div>

        <section class="content-block card fade-in-up">
            <p><strong>원-핫 인코딩</strong>은 단어를 표현하는 가장 기초적이고 직관적인 방법입니다.<br> 전체 단어장에서 각 단어에 고유한 번호를 부여한 뒤,<br> 해당 번호의 위치만 '핫(hot)'하게 <strong>1로 켜고 나머지는 모두 0으로 끄는</strong> 방식입니다.</p>
            
            <h3>작동 방식</h3>
            <aside>
                <ol>
                    <li><strong>단어장(Vocabulary) 생성</strong><br>: 전체 텍스트에서 고유한 단어들을 모두 모아 '단어:고유번호' 형태의 사전을 만듭니다.</li>
                    <li><strong>정수 인코딩(Indexing)</strong><br>: 단어장의 각 단어에 0부터 시작하는 고유 정수(Index)를 할당합니다.</li>
                    <li><strong>벡터 변환</strong><br>: 단어장 크기와 동일한 차원의 0으로 채워진 벡터를 생성한 뒤,<br> 해당 단어의 인덱스 위치 값만 1로 변경합니다.</li>
                </ol>
            </aside>

            <h3>특징과 명확한 한계</h3>
            <p>이 방식은 간단하지만 두 가지 명확한 한계를 가집니다.</p>
            <aside>
                <ol>
                    <li><strong>고차원 / 희소 벡터 (Sparsity)</strong><br>: 단어 수가 3만 개면 벡터의 차원도 3만 차원이 됩니다. 단 하나의 값만 1이고 나머지는 모두 0이므로, <b>메모리 낭비가 심하고 계산이 비효율적입니다.</b></li>
                    <li><strong>의미 관계 표현 불가</strong><br>: 모든 단어 벡터는 서로 수학적으로 독립적(orthogonal)입니다. 이 때문에 '컴퓨터'와 '노트북' 사이의 관계나 '컴퓨터'와 '사과' 사이의 관계에 아무런 차이가 없습니다.<br> <b>즉, 벡터만으로는 단어 간의 의미적 유사성을 전혀 계산할 수 없습니다.</b></li>
                </ol>
            </aside>
        </section>

        <div class="content-block card highlight-gray fade-in-up">
            <h3>예시 : 원-핫 벡터의 한계</h3>
            <p>단어장 : {'사과':0, '바나나':1, '컴퓨터':2, '노트북':3}</p>
            <ul>
                <li>사과 : <code>[1, 0, 0, 0]</code></li>
                <li>컴퓨터 : <code>[0, 0, 1, 0]</code></li>
                <li>노트북 : <code>[0, 0, 0, 1]</code></li>
            </ul>
            <aside>
                <p><strong>문제점 :</strong><br> '컴퓨터'와 '노트북' 사이의 거리와 '컴퓨터'와 '사과' 사이의 거리가 수학적으로 동일합니다. 이는 단어 간의 의미 관계를 전혀 표현하지 못함을 보여줍니다.</p>
            </aside>
        </div>
        <p class="transition-text fade-in-up">이러한 한계점을 극복하기 위해 등장한 것이 바로 <strong>워드 임베딩(Word Embedding)</strong> 기술입니다.</p>
        
        <div class="section-title fade-in-up">
            <h2>2. 워드 임베딩 (Word Embedding)</h2>
        </div>
        
        <section class="content-block card fade-in-up">
            <p><strong>워드 임베딩</strong>은 원-핫 인코딩의 한계를 극복하기 위해 등장한 기술로,<br> 각 단어를 사용자가 지정한 저차원(예: 100~300차원)의 <strong>밀집 벡터(Dense Vector)</strong>로 표현합니다.<br> 이 벡터는 0과 1이 아닌, 단어의 문법적, 의미적 정보를 압축하여 담고 있는 실수들로 채워져 있습니다.</p>
            <aside>
                <h4>핵심 아이디어</h4>
                <ul>
                    <li><strong>분산 표현 (Distributed Representation)</strong><br>: 단어의 의미를 벡터의 여러 차원에 걸쳐 분산시켜 표현합니다.</li>
                    <li><strong>의미적 유사도</strong><br>: 의미가 비슷한 단어들은 벡터 공간상에서 서로 가까운 위치에 존재하게 됩니다.<br> 이를 통해 모델은 단어 간의 관계를 학습하고 추론할 수 있습니다.</li>
                </ul>
            </aside>
        </section>

        <div class="content-block card highlight-gray fade-in-up">
            <h3>예시: 의미를 담은 벡터</h3>
            <p>워드 임베딩은 벡터 간의 연산을 통해 의미 관계를 파악할 수 있습니다.</p>
            <ul>
                <li><strong>유사도 계산 :</strong><br>
                    cosine_similarity('컴퓨터', '노트북') → <strong>높음 (예: 0.92)</strong><br>
                    cosine_similarity('컴퓨터', '사과') → <strong>낮음 (예: 0.15)</strong>
                </li>
                <li style="margin-top: 1rem;"><strong>관계 유추 :</strong><br>
                    <code>vector('왕') - vector('남자') + vector('여자') ≈ vector('여왕')</code>
                </li>
            </ul>
             <aside>
                <p><strong>해결 :</strong><br> 벡터의 거리와 방향을 통해 '컴퓨터'와 '노트북'이 '사과'보다 훨씬 가깝다는 것을 명확히 알 수 있으며, 단어 간의 추상적인 관계까지 계산할 수 있습니다.</p>
            </aside>
        </div>

        <p class="transition-text fade-in-up">
            결론적으로, <strong>원-핫 인코딩</strong>은 단어를 기계가 읽을 수 있는 형태로 바꾸는 첫 걸음이었지만, 의미를 담지 못하는 명확한 한계가 있었습니다.<strong>워드 임베딩</strong>은 이러한 한계를 극복하고 단어의 '의미'를 벡터 공간의 '좌표'로 표현하는 혁신적인 발전을 이루었습니다. 이 개념은 오늘날 BERT, GPT와 같은 거의 모든 현대 자연어 처리 모델의 근간이 되는 핵심 아이디어입니다.
        </p>
        </main>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const animatedElements = document.querySelectorAll('.fade-in-up');

            if ('IntersectionObserver' in window) {
                const observer = new IntersectionObserver((entries) => {
                    entries.forEach(entry => {
                        if (entry.isIntersecting) {
                            entry.target.classList.add('visible');
                            observer.unobserve(entry.target);
                        }
                    });
                }, {
                    threshold: 0.1
                });

                animatedElements.forEach(el => {
                    observer.observe(el);
                });
            } else {
                animatedElements.forEach(el => {
                    el.classList.add('visible');
                });
            }
        });
    </script>

</body>
</html>