<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Teacher Forcing 이해하기</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@300;400;500;700&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary-text-color: #212529;
            --secondary-text-color: #6c757d;
            --background-color: #ffffff;
            --conceptual-card-bg: #f8f9fa;
            --sub-card-bg: #ffffff;
            --border-color: #e9ecef;
            --shadow-color: rgba(0, 0, 0, 0.05);
            --hover-shadow-color: rgba(0, 0, 0, 0.1);
        }

        body {
            font-family: 'Noto Sans KR', sans-serif;
            margin: 0;
            padding: 40px 20px;
            background-color: var(--background-color);
            color: var(--primary-text-color);
            line-height: 1.7;
            font-weight: 400;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
        }

        h1, h2 {
            text-align: center;
            font-weight: 700;
        }

        h1 {
            font-size: 2.5rem;
            margin-bottom: 2.5rem;
        }

        h2 {
            font-size: 1.75rem;
            margin-top: 4rem;
            margin-bottom: 2rem;
            color: var(--primary-text-color);
        }

        h3 {
            font-size: 1.3rem;
            font-weight: 700;
            margin-top: 0;
            margin-bottom: 1rem;
        }
        
        h4 {
            font-size: 1.1rem;
            font-weight: 500;
            margin-top: 0;
            margin-bottom: 0.5rem;
        }

        p {
            margin: 0 0 1rem 0;
            color: var(--primary-text-color);
        }

        hr {
            border: none;
            height: 1px;
            background-color: #dee2e6;
            margin: 4rem auto;
        }

        .card {
            border: 1px solid var(--border-color);
            border-radius: 12px;
        }

        .conceptual-card {
            background-color: var(--conceptual-card-bg);
            padding: 2.5rem;
            box-shadow: 0 4px 6px var(--shadow-color);
            transition: transform 0.3s ease-in-out, box-shadow 0.3s ease-in-out;
        }

        .card.conceptual-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 8px 15px var(--hover-shadow-color);
        }
        
        .sub-card {
            background-color: var(--sub-card-bg);
            border: 1px solid var(--border-color);
            border-radius: 8px;
            padding: 1.5rem;
            box-shadow: 0 2px 4px var(--shadow-color);
        }
        
        .card-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 1.5rem;
            margin-top: 1.5rem;
        }

        .section-divider {
             border: none;
            height: 1px;
            background-color: #dde2e7;
            margin: 2.5rem auto;
            width: 100%;
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 2rem;
            }
            h2 {
                font-size: 1.5rem;
            }
            .card-grid {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>

    <div class="container">
        <h1>Teacher Forcing 이란? (훈련 기법)</h1>

        <div class="card conceptual-card">
            <h3><b>Teacher Forcing(교사 강요)</b></h3>
            <p>
                <b>Teacher Forcing(교사 강요)</b>은<br> RNN이나 GPT와 같은 Auto-regressive(자기회귀) 모델을 위한 <b>훈련(Training) 기법</b>입니다. 
                <br>Auto-regressive 모델은 이전 시점(t-1)의 출력값을 현재 시점(t)의 입력값으로 사용하여 순차적으로 결과를 생성합니다. 
                <br>하지만 훈련 초기에 모델의 예측은 부정확할 가능성이 높습니다. 만약 이 부정확한 예측값을 다음 입력으로 사용하면, 첫 단추를 잘못 끼운 것처럼 오류가 연쇄적으로 누적되어 훈련이 불안정해집니다.
            </p>
            <p>
                Teacher Forcing은 이 문제를 해결하기 위해, 훈련 과정에서 모델이 이전 시점에 무엇을 예측했는지와 상관없이, 
                다음 시점의 입력으로 항상 <b>'실제 정답(Ground Truth)'</b> 단어를 강제로 넣어주는 방식입니다.
            </p>
            <div class="card-grid">
                <div class="sub-card">
                    <h4><b>1. 예측 및 손실 계산</b></h4>
                    <p>
                        모델은 현재 입력을 보고 다음 단어를 예측(output)하고, 이 예측값은 실제 정답과 비교되어 <b>손실(Loss)</b>이 계산됩니다. 이 손실을 통해 모델의 가중치가 업데이트(학습)됩니다.
                    </p>
                </div>
                <div class="sub-card">
                    <h4><b>2. 입력 강제</b></h4>
                    <p>
                        다음 단어를 예측하기 위한 입력(input)으로는, 모델이 방금 예측한 값(오답일 수 있는)을 무시하고 <b>'실제 정답'</b> 단어를 강제로 사용합니다.
                    </p>
                </div>
            </div>
             <p style="margin-top: 1.5rem; margin-bottom: 0;">
                이를 통해 모델은 매 스텝마다 정답 경로 위에서 안정적으로 학습할 수 있으며,<br>모든 타임스텝의 계산을 병렬적으로 처리할 수 있어 학습 속도가 매우 빨라집니다.
            </p>
        </div>

        <hr>

        <h2>문제점 : 학습과 추론의 불일치 문제 (Exposure Bias)</h2>
        <div class="card conceptual-card">
            <p>
                Teacher Forcing은 효율적인 훈련을 가능하게 하지만, 근본적인 문제점을 야기합니다. 
                <br>바로 <b>학습 환경</b>과 실제 <b>추론 환경</b>이 달라지는 것입니다.
            </p>
            <div class="card-grid">
                <div class="sub-card">
                    <h4><b>학습 (Training)</b></h4>
                    <p>
                        모델은 Teacher Forcing 덕분에 항상 완벽한 정답 문장에만 노출됩니다. 
                        마치 모범 답안지만 보고 공부하는 것과 같습니다. 
                        <br>이때는 forward() 함수가 사용됩니다.
                    </p>
                </div>
                <div class="sub-card">
                    <h4><b>추론 (Inference)</b></h4>
                    <p>
                        실제 문장을 생성할 때는 정답이 없으므로, 모델 자신이 생성한 (불완전할 수 있는) 단어를 다음 입력으로 사용해야 합니다. 
                        <br>이때는 generate() 와 같은 별도의 함수가 필요합니다.
                    </p>
                </div>
            </div>
            <p style="margin-top: 1.5rem; margin-bottom: 0;">
                이러한 불일치를 <b>Exposure Bias(노출 편향)</b>라고 합니다. 훈련 중에는 한 번도 경험해보지 못한, 자기 스스로 만든 불완전한 데이터에 노출되면서 예측 오류가 시작되고, 이 오류가 다음 예측에 계속 누적되어 결과물의 품질이 저하될 수 있습니다.
                <br>이 때문에 개발자는 <b>학습용 forward() 함수와 추론용 generate() 함수를 반드시 다르게 구현</b>해야 합니다.
            </p>
        </div>

        <hr>

        <h2><b>어텐션(Attention)</b> vs. <b>티쳐 포싱(Teacher Forcing)</b></h2>
        <div class="card conceptual-card">
            <p>
                두 개념은 <b>생성 모델의 디코더(Decoder)</b>에서 함께 사용되지만, 완전히 다른 문제를 해결하는 독립적인 요소입니다.
            </p>
            <div class="card-grid">
                <div class="sub-card">
                    <h4><b>어텐션 (Attention)</b></h4>
                    <p>
                        모델의 <b>'구조(Architecture)’</b>에 해당하며, <b>'입력(Source) 문장'</b>에서 현재 예측에 중요한 정보가 무엇인지 알려줍니다.
                    </p>
                </div>
                <div class="sub-card">
                    <h4><b>티쳐 포싱 (Teacher Forcing)</b></h4>
                    <p>
                        모델의 <b>'훈련 기법(Technique)'</b>이며, <b>'출력(Target) 문장'</b>을 만들 때 이전 스텝의 정보를 무엇으로 할지 결정합니다.
                    </p>
                </div>
            </div>
            <div class="section-divider"></div>
            <h3>어떻게 함께 작동하는가?</h3>
            <p>
                어텐션을 사용하는 Seq2Seq 모델의 디코더가 단어를 생성하는 순간을 예로 들면 다음과 같습니다.
            </p>
             <div class="sub-card">
                <p><b>(1). Teacher Forcing의 역할</b><br>
                현재 단어를 예측하기 위해, 이전 시점의 <b>입력</b>으로 <b>실제 정답 단어</b>를 공급합니다.
                </p>
                <p><b>(2). Attention의 역할</b><br>
                디코더는 (1)에서 받은 정보<b>(은닉 상태)</b>를 바탕으로, 전체 입력 문장을 다시 참조합니다. 그리고 현재 단어를 예측하는 데 가장 관련성이 높은 입력 단어에 <b>'집중'</b>하여 핵심 문맥 정보를 가져옵니다.
                </p>
                <p style="margin-bottom: 0;"><b>(3). 최종 예측</b><br>
                디코더는 <b>[Teacher Forcing이 준 이전 정답]</b>과 <b>[Attention이 찾아낸 중요 입력 정보]</b>를 모두 종합하여<br>현재 단어를 예측합니다.
                </p>
            </div>
        </div>

    </div>

</body>
</html>